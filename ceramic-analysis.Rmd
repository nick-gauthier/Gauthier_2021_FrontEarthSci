---
title: "Supplemental Information"
subtitle: 'Analysis scripts for "Drought Variability and the Robustness of Agrarian Social Networks"'
author: "Nicolas Gauthier"
date: "Last knit on: `r format(Sys.time(), '%d %B, %Y')`"
#bibliography: bibliography.bibtex
output:
  tufte::tufte_handout:
    citation_package: natbib
    toc: true
    #highlight: pygments
    
  tufte::tufte_html:
    tufte_features: ["fonts", "italics"]
    toc: true
link-citations: yes
monofont: courier
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE}
library(raster)
library(tidyverse)
library(sf)
library(philentropy)
library(tidygraph)
#devtools::install_github('thomasp85/ggraph') # get the dev version
library(ggraph)
```

```{r include = FALSE}
theme_set(theme_bw())
```

# Network Analysis: Spatial Interaction Modeling

Now we move on to the archaeological social network proxies.^[Go to http://www.southwestsocialnetworks.net for more information on this dataset and the project] First we read in a csv file containing information for all of the archaeological sites in the database, including spatial location and number of rooms present from each time period. These will become the node-level data for the network.

```{r}
crs_utm <- '+proj=utm +zone=12 +datum=NAD27'
```

```{r, message = FALSE}
sites <- read_csv('data/attributes_orig.csv') %>%
  st_as_sf(coords = c('EASTING', 'NORTHING'), crs = crs_utm) %>%
  st_transform('+proj=longlat +datum=WGS84')
```

```{r, echo = FALSE}
knitr::kable(
  sites[1:3,c(1:4,8:10)], caption = 'A subset of the node level data.'
)
```
Next we get the apportioned ceramic ware counts per site.
```{r}
load('ware_matrices')

wares <- list(AD1200cer, 
              AD1250cer, 
              AD1300cer, 
              AD1350cer, 
              AD1400cer) %>%
  purrr::map(rownames_to_column) %>%
  bind_rows(.id = 'time') %>%
  mutate(time = as.numeric(time) * 50 + 1150) %>%
  rename(site = rowname)
```

```{r}
wares %>%
  gather(ware, count, 3:38) %>%
  group_by(ware, time) %>%
  summarise(count = sum(count)) %>%
ggplot(aes(time, count, fill = ware, group = ware)) +
  geom_bar(position='fill', stat = 'identity', color = 'black')
```


```{r}
ggplot(sites) +
  geom_sf(aes(color = Macro))
```

Next we aggregate the sites into 10x10km patches. First import and crop the raster we'll use as a reference.
```{r}
elev <- raster('~/SRTM_W_250m_TIF/SRTM_W_250m.tif') %>% # import the SRTM DEM
  crop(extent(c(-113, -107, 31, 37.5))) %>% # crop to study area
  aggregate(fact = 40) # aggregate to 10km resolution
```

```{r}
#from https://stackoverflow.com/a/46846474
calculate_mode <- function(x) {
  uniqx <- unique(x)
  uniqx[which.max(tabulate(match(x, uniqx)))]
}
```

```{r}
patches <- sites %>%
  mutate(., patch_id = as.character(cellFromXY(elev, st_coordinates(.)))) %>%
  gather(period, rooms, P1room:P5room) %>%
  mutate(time = parse_number(period) * 50 + 1150) %>%
  group_by(patch_id, time) %>%
  summarise(Macro = calculate_mode(Macro),
            site = list(SWSN_Site),
            rooms = sum(rooms)) %>%
  ungroup %>%
  spread(time, rooms) %>%
  cbind(., xyFromCell(elev, as.numeric(.$patch_id))) %>%
  as.data.frame %>%
  st_as_sf(coords = c('x','y'), crs = 4326, remove = FALSE)
```

```{r}
patches %>%
  gather(time, rooms, X1200:X1400) %>%
  mutate(time = parse_number(time)) %>%
  group_by(Macro, time) %>%
  summarise(rooms = sum(rooms)) %>%
ggplot(aes(time, rooms, group = Macro, color = Macro)) +
  geom_line()

patches %>%
  gather(time, rooms, X1200:X1400) %>%
  mutate(time = parse_number(time)) %>%
  group_by(Macro, time) %>%
  summarise(rooms = sum(rooms)) %>%
  mutate(rooms = rooms / max(rooms)) %>%
ggplot(aes(time, rooms, group = Macro, color = Macro)) +
  geom_line()
```

```{r}
patches %>%
  gather(time, rooms, X1200:X1400) %>%
  mutate(time = parse_number(time)) %>%
  filter(rooms > 0) %>%
ggplot() +
  geom_sf(aes(color = Macro, size = rooms, fill = Macro)) +
  scale_size_area() +
  facet_wrap(~time)
```

```{r}
getJSD <- function(data, time){
  patch_ids <- pull(data, patch_id)
  data %>%
    select(-patch_id) %>%
    select_if(~!all(. == 0)) %>%
    as.matrix %>%
    philentropy::distance(method = 'jensen-shannon', est.prob = 'empirical') %>%
    `/`(., max(.)) %>%
    `-`(1,.) %>%
    `rownames<-`(patch_ids) %>%
    `colnames<-`(patch_ids) %>%
    replace(. == 0, 999) %>% # replace 0 values with 999 temporarily
    as_tbl_graph %E>% # convert to directed graph
    rename(JSD = weight) %>%
    mutate(JSD = if_else(JSD == 999, 0, JSD)) %>% # convert 999 values back to 0
    mutate(time = time) %>% # set the time period
    filter(!edge_is_loop()) %>%
  activate(nodes) 
}
```

```{r}
swsn <- patches %>%
  gather(time, rooms, X1200:X1400) %>%
  mutate(time = parse_number(time)) %>%
  select(patch_id, site, time) %>%
  unnest(site) %>%
  right_join(wares) %>%
  as.data.frame %>%
  select(-site, -geometry) %>%
  group_by(time, patch_id) %>%
  summarise_all(sum, na.rm = T) %>%
  nest %>%
  mutate(net = map2(data, time, getJSD)) %>%
  pull(net) %>%
  reduce(graph_join, by = 'name') %>%
  left_join(patches, by = c('name' = 'patch_id'))
```

```{r}
states <- maps::map('state', regions = c('arizona', 'new mexico'), 
                    fill = TRUE, plot = FALSE) %>%
  st_as_sf
```

```{r fig.fullwidth = TRUE, fig.width = 7, fig.height = 4}
swsn %E>% 
    filter(JSD > .001) %>%
    filter(from < to) %>%
    #mutate(JSD = qlogis(if_else(JSD > .999, .999, JSD))) %>%
    arrange(JSD) %>%
ggraph('manual', x = x, y = y) +
  geom_edge_fan(aes( color = JSD)) +
  geom_sf(data = states, fill = NA, color = 'black') +
  facet_edges(~time, ncol = 3) +
  scale_edge_alpha(guide = 'none', limits = c(0,1)) +
  scale_edge_color_viridis(name = 'JSD', option = 'magma', limits = c(0,1)) +
  #scale_edge_color_distiller(palette = 'RdYlBu', guide = 'legend', name = 'JSD',limits = c(0,1)) +
  coord_sf(datum = NA) +
  theme_void() +
  theme(legend.position = c(1, 0), legend.justification = c(2.5,0))

ggsave('figures/JSD_network.png', width = 7, height = 4)
```

```{r}
saveRDS(swsn, 'output/swsn')
```

```{r}
knitr::knit_exit()
```

What follows is the original way of processing the data on all sites, not just patches. Its saved here for comparison

Next import the edge data. Our data come in the form of JSD matrices, one for each time step. We need to define a function for importing and processing a single time step of the edge datasets. This function imports the csv, turns it into a matrix, and then a directed graph. 

```{r read_swsn}
read_swsn <- function(net, time){
  read.csv(net, row.names = 1, check.names = FALSE) %>% 
    as.matrix %>% # convert to a matrix
    replace(. == 0, 999) %>% # replace 0 values with 999 temporarily
    as_tbl_graph(directed = TRUE) %E>% # convert to directed graph
    mutate(weight = if_else(weight == 999, 0, weight)) %>% # convert 999 values back to 0
    rename(JSD = weight) %>% # rename the edge weights
    filter(!edge_is_loop()) %>% # remove self loops
    mutate(time = 1150 + 50 * time) %>%  # set the time period
    activate('nodes') # activate node data
}
```


Next we map this function over a lists of simlaritity matrices. Get a list of the JSD files, map the above function over them, reduce to a single graph.  Use reduce and graph join to combiine all of these networks into a single netwtork, retaining the edge weights for each  separate period.

Start by getting a list of the JSD file names, map the read_swsn function over these files, combine into a single graph using the reduce function, and then join to the site database.

```{r swsn_import}
swsn2 <- list.files('data/wares/', full.names = TRUE) %>%
  imap(read_swsn) %>%
  reduce(graph_join, by = 'name') %>%
  left_join(sites, by = c('name' = 'SWSN_Site')) 
```

Comparing the two approaches show that the using the coarse grained patches approach reduces the number of long distance strong connections. This is likely do to the fact htat we're removing the impact of small sites with only one or two ware types, which can introduce spurious high correlations.
```{r}
swsn %E>% 
    filter(JSD > .001) %>%
    filter(from < to) %>%
    mutate(JSD = qlogis(if_else(JSD > .999, .999, JSD))) %>%
    arrange(JSD) %>%
ggraph('manual',node.positions = as.data.frame(swsn)) +
  geom_edge_fan(aes( color = JSD)) +
        geom_sf(data = states, fill = NA, color = 'black') +
  facet_edges(~time, ncol = 3) +
  scale_edge_alpha(guide = 'none') +
  #scale_edge_color_viridis(name = 'JSD', option = 'magma') +#, limits = c(0,1)
  scale_edge_color_distiller(palette = 'RdYlBu', guide = 'legend', name = 'JSD') +
  coord_sf(datum = NA) +
  theme_void() +
  theme(legend.position = c(1, 0),legend.justification = c(2.5,0))
swsn2 %E>% 
    filter(JSD > .001) %>%
    filter(from < to) %>%
    mutate(JSD = qlogis(if_else(JSD > .999, .999, JSD))) %>%
    arrange(JSD) %>%
ggraph('manual',node.positions = as.data.frame(pts)) +
  geom_edge_fan(aes( color = JSD)) +
        geom_sf(data = states, fill = NA, color = 'black') +
  facet_edges(~time, ncol = 3) +
  scale_edge_alpha(guide = 'none') +
  #scale_edge_color_viridis(name = 'JSD', option = 'magma') +#, limits = c(0,1)
  scale_edge_color_distiller(palette = 'RdYlBu', guide = 'legend', name = 'JSD') +
  coord_sf(datum = NA) +
  theme_void() +
  theme(legend.position = c(1, 0),legend.justification = c(2.5,0))
```


