---
title: "sw_networks"
author: "Nick Gauthier"
date: "June 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
Load the necessary packages.
```{r message = F}
library(raster)
library(tidyverse)
library(rgdal)
library(gdistance)
library(wql)
library(tidygraph)
library(ggraph)
library(mgcv)
```


## Empiricial Orthogonal Functions
First we estimate present and past climate patterns
Define a boundary box for the western US
```{r}
bbox_wus <- extent(c(-124, -105, 31, 41))
```

Import high resolution SPEI maps generated from prism data. Calculate the average summertime (JJA) SPEI value for each year.
```{r observation-import, warning = F, message=F}
spei_obs <- ((brick('Data/spei12_6_PRISM.nc') + 
              brick('Data/spei12_7_PRISM.nc') + 
              brick('Data/spei12_8_PRISM.nc')) / 3) %>%
  crop(bbox_wus) %>%
  `names<-`(1895:2017) %>%
  .[[2:105]]  # remove the first value becuase spei needs a year lag time to calculate. 
```

Import the reconstructed SPEI data.
```{r phyda-import}
spei_recon <- brick('Data/da_hydro_JunAug_r.1-2000_d.05-Jan-2018.nc', varname = 'spei_mn') %>%
   .[[1100:1999]] %>%
   rotate %>%
   crop(bbox_wus, snap = 'out')
```

Plotting out the time series of the reconstruction reveals no clear trend in the mean. It does, however, show a pattern of increasing variance over time, which is entirely a function of the changing number of proxies used in the data assimilaiton approach.
```{r echo = F}
spei_recon %>% 
  as.data.frame(xy = T, na.rm = T) %>%
  gather(year, value, 3:902) %>%
  mutate(year = str_sub(year, 2),
         year = as.numeric(year)) %>%
  ggplot(aes(year, value)) +
  geom_line(alpha = .1, aes(group = interaction(x, y))) +
  geom_smooth() +
  ggtitle('Standardized Precipitation-Evapotranspiration Index in the American Southwest',
          'June-August, 12 month lag') +
  theme_bw()
```

Look at the variances for the eofs of each field, to inform truncation. Let's retain the leading four modes from PHYDA
```{r echo = F}
spei_recon %>%
  as.data.frame(na.rm = T) %>%
  t %>%
  eofNum(scale. = F)
```
Repeat for the prism observations. Again, we'll retain the leading four modes.
```{r echo = F}
#this code is the same as the eofNum function above, but needs a slight adjustment here because that function assumes more time than spatial indices
eigs <- prcomp(t(as.data.frame(spei_obs, na.rm = T)), scale. = F)[["sdev"]]^2
eigs.pct <- 100 * eigs/sum(eigs)
eigs.lo <- eigs * (1 - sqrt(2/104))
eigs.hi <- eigs * (1 + sqrt(2/104))
cumvar <- round(cumsum(eigs.pct), 1)
p <- 104
d <- data.frame(rank = factor(1:p), eigs, eigs.lo, eigs.hi, 
        cumvar)
d <- within(d, cumvar.line <- eigs.hi + 0.02 * max(eigs.hi))
d <- d[1:min(p, 10), ]
ggplot(data = d, aes(x = rank, y = eigs)) + geom_errorbar(aes(x = rank, 
        ymin = eigs.lo, ymax = eigs.hi), width = 0.3) + geom_point(size = 3) + 
        geom_text(aes(x = rank, y = cumvar.line, label = cumvar), 
            size = 3, vjust = 0) + labs(list(x = "Rank", y = "Eigenvalue")) + 
        theme(panel.grid.minor = element_blank())
```
The standard errors on the above plots assume there is no autocorrelation. Check to see if that is indeed the case.
```{r echo = F}
spei_recon %>%
  as.data.frame(na.rm = T) %>%
  t %>%
  as_tibble %>%
  gather(key, value) %>%
  pull(value) %>%
  acf

spei_obs %>%
  as.data.frame(na.rm = T) %>%
  t %>%
  as_tibble %>%
  gather(key, value) %>%
  pull(value) %>%
  acf
```
It looks like there is some autocorrelaiton, will have to adjust in the future.


Now, calculate the eofs for both fields, retaining the 4 leading components in each case for rotation
```{r}
n_modes <- 4

obs_eof <- spei_obs %>%
  as.data.frame(na.rm = T) %>%
  t %>%
  eof(n_modes, scale. = F)

recon_eof <- spei_recon %>%
  as.data.frame(na.rm = T) %>%
  t %>%
  eof(n_modes, scale. = F)
```

```{r echo = F}
as.data.frame(spei_obs[[1]], xy = T, na.rm = T) %>% cbind(obs_eof$REOF) %>%
  select(-3) %>%
  gather(eof, value, 3:(n_modes + 2)) %>%
  ggplot(aes(x,y)) +
  geom_raster(aes(fill = value)) +
    scale_fill_distiller(palette = 'BrBG', direction = 1, limits = c(-1, 1)) +
  facet_wrap(~eof) +
  theme_void() +
  coord_quickmap()
```

```{r echo = F}
as.data.frame(spei_recon[[1]], xy = T, na.rm = T) %>% cbind(recon_eof$REOF) %>%
  select(-3) %>%
  gather(eof, value, 3:(n_modes+2)) %>%
  ggplot(aes(x,y)) +
  geom_raster(aes(fill = value)) +
    scale_fill_distiller(palette = 'Spectral', direction = 1, limits = c(-1, 1)) +
  facet_wrap(~eof) +
  theme_void() + 
  coord_quickmap()
```
Look at the correlations between the modes.
```{r message = F, echo = F}
amplitudes <- left_join(
  recon_eof$amplitude %>%
    .[797:900,] %>%
    as_tibble %>%
    mutate(year = 1896:1999) %>%
    gather(eof, recon, 1:n_modes),
  obs_eof$amplitude %>%
    as_tibble %>%
    mutate(year = 1896:1999) %>%
    gather(eof, obs, 1:n_modes))
```

```{r echo = F}
ggplot(amplitudes, aes(recon, obs)) +
  geom_point(aes(color = year)) +
  geom_smooth(method = 'lm') +
  scale_color_viridis() +
  facet_wrap(~eof) +
  ggtitle('Linear fits between observed and reconstructed amplitudes', '1896-1999') +
  theme_minimal() +
  coord_fixed()
```

Now let's fit these models in practice. First create a data frame of past amplitudes.
```{r}
past_amplitudes <- recon_eof$amplitude %>%
    as_tibble %>%
    mutate(year = 1100:1999) %>%
    gather(eof, recon, 1:n_modes) %>%
  group_by(eof) %>%
  nest(.key = 'recons')
```

```{r echo = F, eval F}
phyda <- ncdf4::nc_open('Data/da_hydro_JunAug_r.1-2000_d.05-Jan-2018.nc')
cor(ncdf4::ncvar_get(phyda, 'PacDelSST_mn')[1100:1999], recon_eof$amplitude[,1])
cor(ncdf4::ncvar_get(phyda, 'PacDelSST_mn')[1100:1999], recon_eof$amplitude[,2])
cor(ncdf4::ncvar_get(phyda, 'PacDelSST_mn')[1100:1999], recon_eof$amplitude[,3])
cor(ncdf4::ncvar_get(phyda, 'PacDelSST_mn')[1100:1999], recon_eof$amplitude[,4])

plot(ncdf4::ncvar_get(phyda, 'Pac130_mn')[1100:1999], recon_eof$amplitude[,2])
plot(ncdf4::ncvar_get(phyda, 'Pac130_mn')[1100:1999], recon_eof$amplitude[,3])
cor(ncdf4::ncvar_get(phyda, 'Pac160_mn')[1100:1999], recon_eof$amplitude[,2])
cor(ncdf4::ncvar_get(phyda, 'Pac160_mn')[1100:1999], recon_eof$amplitude[,3])
cor(ncdf4::ncvar_get(phyda, 'Pac160_mn')[1100:1999], recon_eof$amplitude[,4])
cor(ncdf4::ncvar_get(phyda, 'amo_mn')[1100:1999], recon_eof$amplitude[,2])
cor(ncdf4::ncvar_get(phyda, 'amo_mn')[1100:1999], recon_eof$amplitude[,3])
cor(ncdf4::ncvar_get(phyda, 'Atl_mn')[1100:1999], recon_eof$amplitude[,1])
cor(ncdf4::ncvar_get(phyda, 'Atl_mn')[1100:1999], recon_eof$amplitude[,2])
cor(ncdf4::ncvar_get(phyda, 'Atl_mn')[1100:1999], recon_eof$amplitude[,3])
cor(ncdf4::ncvar_get(phyda, 'EPac_mn')[1100:1999], recon_eof$amplitude[,4])
```

```{r message = F}
recon_amplitudes <- amplitudes %>%
  group_by(eof) %>%
  nest %>%
  mutate(mod = map(data, ~gam(obs ~ s(recon, bs = 'cr'), data = ., method = 'REML', select = T))) %>%
  left_join(past_amplitudes) %>%
  mutate(predictions = map2(mod, recons, ~predict(.x, .y, type = 'response')),
         predictions = map(predictions, ~.[1:400]),
         predictions = map(predictions, ~tibble(year = 1100:1499, amplitude = .)),
         predictions = map(predictions, ~mutate(., amp_smooth = zoo::rollmean(amplitude, k = 51, fill = NA)))) %>%
  select(eof, predictions) %>%
  unnest %>%
  mutate(period = floor((year/50)) * 50) 
```


```{r echo = F}
ggplot(recon_amplitudes, aes(year, amplitude, group = eof)) +
  geom_line(aes(color = eof), alpha = .7) +
  geom_line(aes(y = amp_smooth)) +
  scale_color_brewer(palette = 'Spectral') +
  facet_wrap(~eof) +
  theme_minimal()
```

```{r}
recon_amplitudes %>%
  filter(between(period, 1200, 1400)) %>%
  ggplot(aes(factor(period), amplitude)) +
  geom_boxplot() +
  geom_hline(yintercept = 0, color = 'red', linetype = 2) +
  scale_color_brewer(palette = 'Spectral') +
  facet_wrap(~eof) +
  theme_minimal()
```

## Data import and preprocessing
Import the node data.
```{r message = F}
node_data <- read_csv('Data/attributes_orig.csv')
```

Define a function for importing and processing a single time step of the edge datasets.
```{r}
read_swsn <- function(net, time){
  read.csv(net, row.names = 1, check.names = F) %>%
    as.matrix %>%
    as_tbl_graph(directed = T) %E>%
    rename(similarity = weight) %>%
    filter(!edge_is_loop()) %N>%
    mutate(centrality = centrality_eigen(weights = similarity)) %E>%
    mutate(time = 1150 + 50 * time,
           centrality_from = .N()$centrality[from],
           centrality_to = .N()$centrality[to]) %N>%
    select(-centrality)
}
```

Get a list of the similarity files, map the above function over them, reduce to a single graph.
```{r}
swsn <- list.files('Data/Sim', full.names = T) %>%
  imap(read_swsn) %>%
  reduce(graph_join, by = 'name') %>%
  left_join(node_data, by = c('name' = 'SWSN_Site'))
```

Create a separate spatial points object, storing the locations of the sites. Convert the coordinates from utm to lat lon, and add back to the original data
```{r}
pts <- swsn %N>% 
  select(x = EASTING, y = NORTHING) %>%
  as_tibble %>%
  SpatialPoints(proj4string=CRS("+proj=utm +zone=12 +datum=NAD27")) %>%
  spTransform(CRS("+proj=longlat +datum=WGS84")) %>% 
  coordinates %>%
  data.frame
```

Add location and size to edge data.
```{r}
dat <- swsn %N>%
  mutate(lon = pts$x, 
         lat = pts$y) %E>%
  mutate(from_x = .N()$lon[from],
         from_y = .N()$lat[from],
         to_x = .N()$lon[to],
         to_y = .N()$lat[to],
         size_from = case_when(time == 1200 ~ .N()$P1room[from],
                               time == 1250 ~ .N()$P2room[from],
                               time == 1300 ~ .N()$P3room[from],
                               time == 1350 ~ .N()$P4room[from],
                               time == 1400 ~ .N()$P5room[from]),
         size_to = case_when(time == 1200 ~ .N()$P1room[to],
                             time == 1250 ~ .N()$P2room[to],
                             time == 1300 ~ .N()$P3room[to],
                             time == 1350 ~ .N()$P4room[to],
                             time == 1400 ~ .N()$P5room[to]),
         macro_from = .N()$Macro[from],
         macro_to =.N()$Macro[to],
         macro_same = macro_from == macro_to,
         micro_from = .N()$Micro[from],
         micro_to = .N()$Micro[to],
         micro_same = micro_from == micro_to) %>%
  as_tibble
```



```{r echo = F, eval = F}
states <- maps::map('state', regions = c('arizona', 'new mexico'), fill = T, plot = F)

ggraph(swsn, 'manual', node.positions = pts) +
  geom_raster(data = gather(as.data.frame(reof_raster, xy = T, na.rm = T), key, value,  3:6), aes(x, y, fill = value)) +
  geom_edge_fan(aes(alpha = similarity, color = similarity)) +
  geom_polygon(data = states, aes(x = long, y = lat, group = region), color = 'black', fill = NA) +
  geom_node_point(aes(size = centrality, color = centrality)) +
  facet_edges(~time) +
  facet_wrap(~key) +
  scale_edge_alpha() +
  scale_fill_distiller(palette = 'Spectral', direction = 1, limits = c(-1, 1)) +
  coord_equal() +
  theme_graph()
```

## Environmental Data
```{r}
bbox <- extent(c(-113.5, -106.5, 31, 37.5))
```

```{r}
elev <- raster('~/Downloads/SRTM_W_250m_TIF/SRTM_W_250m.tif') %>%
  crop(bbox)

prec <- raster('Data/PRISM_ppt_30yr_normal_800mM2_annual_asc.asc') %>% 
  crop(bbox)

temp <- raster('Data/PRISM_tmean_30yr_normal_800mM2_annual_asc.asc') %>%
  crop(bbox)

reof_raster <- as.data.frame(spei_obs[[1]], xy = T, na.rm = T) %>%
  select(x:y) %>%
  cbind(obs_eof$REOF) %>%
  rasterFromXYZ %>%
  `crs<-`('+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0') %>% 
  crop(bbox)
  
env_rasters <- list(elev, prec, temp, reof_raster) %>%
  map(projectRaster, prec) %>%
  brick %>%
  `names<-`(c('elev', 'precip', 'temp', 'reof1', 'reof2', 'reof3', 'reof4'))

pairs(env_rasters)
```

```{r, eval = F, echo = F}
test <- recon_amplitudes %>%
  filter(between(period, 1200, 1400)) %>%
  group_by(eof, period) %>% 
  summarise(amplitude = mean(amplitude))
eof_data <- swsn %N>%
  select(lon, lat) %>%
  as_tibble %>%
  raster::extract(reof_raster, ., df = T) %>%
  gather(eof, value, 2:5) %>%
  full_join(test) %>%
  mutate(key = paste(eof, period, sep = '_'),
            value = value * amplitude) %>%
  select(ID, key, value) %>%
  spread(key, value, -1)
```

```{r}
raster::extract(env_rasters, pts, df = T)
```

```{r}
swsn <- swsn %N>%
  mutate(ID = 1:n()) %>%
  left_join(eof_data) %E>%
  mutate(EOF1_from = case_when(time == 1 ~ .N()$EOF1_1200[from],
                               time == 2 ~ .N()$EOF1_1250[from],
                               time == 3 ~ .N()$EOF1_1300[from],
                               time == 4 ~ .N()$EOF1_1350[from],
                               time == 5 ~ .N()$EOF1_1400[from]),
         EOF1_to = case_when(time == 1 ~ .N()$EOF1_1200[to],
                             time == 2 ~ .N()$EOF1_1250[to],
                             time == 3 ~ .N()$EOF1_1300[to],
                             time == 4 ~ .N()$EOF1_1350[to],
                             time == 5 ~ .N()$EOF1_1400[to]),
         EOF2_from = case_when(time == 1 ~ .N()$EOF2_1200[from],
                               time == 2 ~ .N()$EOF2_1250[from],
                               time == 3 ~ .N()$EOF2_1300[from],
                               time == 4 ~ .N()$EOF2_1350[from],
                               time == 5 ~ .N()$EOF2_1400[from]),
         EOF2_to = case_when(time == 1 ~ .N()$EOF2_1200[to],
                             time == 2 ~ .N()$EOF2_1250[to],
                             time == 3 ~ .N()$EOF2_1300[to],
                             time == 4 ~ .N()$EOF2_1350[to],
                             time == 5 ~ .N()$EOF2_1400[to]),
         EOF3_from = case_when(time == 1 ~ .N()$EOF3_1200[from],
                               time == 2 ~ .N()$EOF3_1250[from],
                               time == 3 ~ .N()$EOF3_1300[from],
                               time == 4 ~ .N()$EOF3_1350[from],
                               time == 5 ~ .N()$EOF3_1400[from]),
         EOF3_to = case_when(time == 1 ~ .N()$EOF3_1200[to],
                             time == 2 ~ .N()$EOF3_1250[to],
                             time == 3 ~ .N()$EOF3_1300[to],
                             time == 4 ~ .N()$EOF3_1350[to],
                             time == 5 ~ .N()$EOF3_1400[to]),
         EOF4_from = case_when(time == 1 ~ .N()$EOF4_1200[from],
                               time == 2 ~ .N()$EOF4_1250[from],
                               time == 3 ~ .N()$EOF4_1300[from],
                               time == 4 ~ .N()$EOF4_1350[from],
                               time == 5 ~ .N()$EOF4_1400[from]),
         EOF4_to = case_when(time == 1 ~ .N()$EOF4_1200[to],
                             time == 2 ~ .N()$EOF4_1250[to],
                             time == 3 ~ .N()$EOF4_1300[to],
                             time == 4 ~ .N()$EOF4_1350[to],
                             time == 5 ~ .N()$EOF4_1400[to])) %>%
  mutate(eof1 = EOF1_from - EOF1_to,
      eof2 = EOF2_from - EOF2_to,
      eof3 = EOF3_from - EOF3_to,
      eof4 = EOF4_from - EOF4_to,
      eof1_same = sign(EOF1_from) == sign(EOF1_to),
      eof2_same = sign(EOF2_from) == sign(EOF2_to),
      eof3_same = sign(EOF3_from) == sign(EOF3_to),
      eof4_same = sign(EOF4_from) == sign(EOF4_to))
```


## Least Cost Distances

```{r cache = T}
altDiff <- function(x){x[2] - x[1]}
hd <- transition(elev, altDiff, 8, symm = F)
cell.targets <- Which(!is.na(elev), cells = T)
adj <- adjacent(elev, cells = cell.targets, target = cell.targets, pairs = T, directions = 8)
slope <- geoCorrection(hd, type = 'c')
rm(hd)
speed <- slope
speed[adj] <- 6 * exp(-3.5 * abs(slope[adj] + 0.05))
rm(slope, adj)
conductance <- geoCorrection(speed, type = 'c')
rm(speed)
```

```{r echo = F, message = F, warning = F}
gc()
```

```{r echo = F}
plot(raster(conductance))
```

Calculate the least cost distance matrix between all sites and turn into a graph.
```{r cache = T}
distances <- swsn %N>%
  select(lon, lat) %>%
  as_tibble %>%
  as.matrix %>%
  costDistance(conductance, .) %>%
  as_tbl_graph(directed = T) %E>%
  rename(distance = weight) %>%
  as_tibble
```

```{r echo = F}
gc()
```
```{r}
saveRDS(distances, 'distances.rds')
loadRDS(distances, 'distances.rds')
```





## Model fitting
```{r}
dat <- swsn %E>%
  left_join(distances) %>%
  as_tibble %>%
   mutate(distance = replace_na(distance, 0)) %>%
  filter(similarity > 0) %>%
  mutate(edge = as.factor(paste(from, to, sep = '-'))) %>%
  mutate(eof1_same = as.factor(eof1_same),
         eof2_same = as.factor(eof2_same),
         eof3_same = as.factor(eof3_same),
         eof4_same = as.factor(eof4_same)) 
```

```{r echo = F}
ggplot(filter(dat, similarity > 0), aes(distance,similarity)) +
  geom_point(alpha = .1) +
  scale_color_distiller(palette = 'Spectral', direction = 1, limits = c(0,1)) +
  geom_smooth() +
  #scale_x_log10()+
  #scale_y_log10()+
  theme_minimal()

ggplot(filter(dat, similarity>0), aes(distance,similarity)) +
  geom_point(alpha = .1, aes(color = local_significance)) +
  scale_color_distiller(palette = 'Spectral', direction = 1, limits = c(0,1)) +
  geom_smooth() +
  theme_minimal()
```

In log log space, we get teh downward function from devries et al 2009!
```{r}
ggplot(filter(dat, local_significance <=.1), aes(distance + .01,similarity + .001)) +
  geom_point(alpha = .1, aes(color = local_significance)) +
  scale_color_distiller(palette = 'Spectral', direction = 1, limits = c(0,1)) +
  geom_smooth() +
  scale_x_log10()+
  scale_y_log10()+
  theme_minimal()
```

```{r}
ggplot(filter(dat, local_significance <=.5 & similarity > 0), aes(distance,similarity)) +
  geom_point(alpha = .1, aes(color = local_significance)) +
  scale_color_distiller(palette = 'Spectral', direction = 1, limits = c(0,1)) +
  geom_smooth() +
  theme_minimal()
```

Do the fits to distance change with time? a little bit, but seems more to have to do with the decreae in sample size with time.
```{r}
ggplot(dat, aes(distance, similarity)) +
  geom_point(alpha = .1, aes(color = time)) +
    scale_color_distiller(palette = 'Spectral', direction = 1) +
  geom_smooth(aes(group = time, color = time)) +
  geom_smooth() +
  theme_minimal()
```

```{r}
ggplot(dat, aes(distance, weighted_similarity)) +
  geom_point(alpha = .1) +
  geom_smooth() +
  theme_minimal()
```

```{r}

ggplot(dat, aes(log((similarity * (nrow(dat) - 1) + .5 )/nrow(dat)) / (1 - (similarity * (nrow(dat) - 1) + .5 )/nrow(dat)))) +
  geom_density()
ggplot(dat, aes(log(-log((1 - (similarity * (nrow(dat) - 1) + .5 )/nrow(dat)))))) +
  geom_density()
dat %>% 
  mutate(group = paste(from, to, sep = '-')) %>%
ggplot(aes(time, similarity, group = group)) +
  geom_line(alpha = .1)

hist(dat$similarity)
```

```{r}
fit_gam <- function(x){
  bam(x, select = T, 
         family = betar(link = 'cloglog', eps = .001,#1/(2*nrow(dat))), # MacMillan and Creelman 2005 pp 8-9
         data = dat)#(dat * (nrow(dat) - 1) + .5) / nrow(dat))
}

geo_models <- c(
    "s(distance, bs = 'cr')",
    "s(distance, bs = 'cr') + s(size, bs = 'cr')",
    "s(distance, bs = 'cr') + s(size_from, size_to)",
    "ti(distance) + ti(size) + ti(distance, size)",
    "te(distance, size, k = 10)",
    "s(distance, bs = 'cr') + s(abs(eof1), bs = 'cr', k = 15) + s(abs(eof2), bs = 'cr') + s(abs(eof3), bs = 'cr', k = 15) + s(abs(eof4), bs = 'cr', k = 15)",
    "s(distance, bs = 'cr') + s(sqrt(abs(eof1)), bs = 'cr', k = 15) + s(abs(eof2), bs = 'cr') + s(abs(eof3), bs = 'cr', k = 15) + s(abs(eof4), bs = 'cr', k = 15)") %>%
  paste('similarity ~', .) %>%
  map(as.formula) %>%
  tibble(formula = .) %>%
  mutate(model = map(formula, fit_gam))

geo_models %>%
  mutate(aic = map_dbl(model, AIC))

summary(geo_models[[6,2]])
plot(geo_models[[7,2]], scheme = 1, residuals = T)
gam.check(geo_models[[6,2]])
hist(sqrt(abs(dat$eof4)))
```

```{r}

```

```{r}
mod5 <- gam(fractional_similarity ~ s(distance, bs = 'cr') +
              s(eof1, bs = 'cr') +
              s(eof2, bs = 'cr') +
              s(eof3, bs = 'cr') +
              s(eof4, bs = 'cr'),
            select = T,
            method = 'REML',
            family = betar(link = 'cloglog'),
            data = dat)

mod6 <- gam(similarity ~ s(distance, bs = 'cr') +
              s(abs(eof1), bs = 'cr') +
              s(abs(eof2), bs = 'cr') +
              s(abs(eof3), bs = 'cr') +
              s(abs(eof4), bs = 'cr'),
            select = T,
            method = 'REML',
            family = betar(link = 'cloglog'),
            data = dat)

summary(mod1)
plot(mod1)
gam.check(mod1)
```


```{r}
mod1.5 <- gam(similarity ~ s(distance, bs = 'cr', k = 30),
            method = 'REML',
            select = T,
            family = betar(link = 'cloglog', eps = .0001),
            data = filter(dat, local_significance <= .5))
summary(mod1.5)
plot(mod1.5, residuals= F)
gam.check(mod1.5)

hist(degree_distribution(swsn %E>% filter(local_significance <= .05 & similarity > 0), mode = 'out'))
swsn %E>%
  filter(time == 1) %>%
  filter(local_significance < .05 & similarity > 0) %N>%
  mutate(degree = centrality_degree(weights = similarity, mode = 'out')) %>%
  as_tibble %>%
  ggplot(aes(degree)) +
  geom_density()



dat %>%
  filter(local_significance <= .05) %>%
  ggplot(aes(similarity)) +
  geom_density() +
  facet_wrap(~time)
```


```{r}
mod2 <- gam(similarity ~ s(distance, bs = 'cr') +
                         s(size_from, bs = 'cr') +
                        s(size_to, bs = 'cr'),
            method = 'REML',
            family = betar(link = 'cloglog'),
            data = dat)


mod7 <- gam(similarity ~ s(distance, bs = 'cr') +
              eof2_same +
              s(eof1, bs = 'cr') +
              s(eof2, bs = 'cr', by = eof2_same) +
              s(eof3, bs = 'cr') +
              s(eof4, bs = 'cr'),
            select = T,
            method = 'REML',
            family = betar(link = 'cloglog'),
            data = dat)
mod8 <- gam(similarity ~ s(distance, bs = 'cr') +
                eof2_same +
              s(abs(eof1), bs = 'cr') +
              s(abs(eof2), bs = 'cr', by = eof2_same) +
              s(abs(eof3), bs = 'cr') +
              s(abs(eof4), bs = 'cr'),
            select = T,
            method = 'REML',
            family = betar(link = 'cloglog'),
            data = dat)

levels(dat$eof4_same)
mod2 <- gamm(similarity * 1000 ~ s(distance, bs = 'cr'),
            method = 'REML',
            family = poisson,
            correlation = corAR1(form = ~time|edge),
            data = dat)

plot(mod1, residuals = T);plot(mod2, residuals = F);plot(mod3, scheme = 1, residuals = T);plot(mod4, scheme = 1);plot(mod5, residuals = F)
plot(mod6);plot(mod7);plot(mod8)
AIC(mod1);AIC(mod2);AIC(mod3);AIC(mod4);AIC(mod5);AIC(mod6);AIC(mod7);AIC(mod8)
gam.check(mod5)
summary(mod7)

gam.check(mod1)
summary(residuals(mod1, type = 'response'))
cbind(dat, test = residuals(mod1)) %>%
  filter(test > 6)
```
```{r}
plot(reof_raster)
```




```{r}
swsn %E>%
  filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[1,2]], type = 'response')) %>%
  filter(resid > .25 | resid < -.25) %>%
  mutate(fac = if_else(resid > 0, 'pos', 'neg')) %>%
  ggraph('manual', node.positions = pts) +
  geom_edge_link(aes(alpha = abs(resid), color = resid)) +
  facet_graph(time ~ fac, col_type = 'edge') +
  geom_polygon(data = states, aes(x = long, y = lat, group = region), color = 'black', fill = NA) +
  scale_edge_colour_distiller(palette = 'RdBu', limits = c(-1,1)) +
  coord_equal() +
  theme_graph()
```
```{r}
swsn %N>%
  filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[6,2]], type = 'response')) %>%
  filter(resid > .25 | resid < -.25) %>%
  mutate(fac = if_else(resid > 0, 'pos', 'neg')) %>%
  ggraph('manual', node.positions = pts) +
  geom_edge_link(aes(alpha = abs(resid), color = resid)) +
  facet_graph(time ~ fac, col_type = 'edge') +
  geom_polygon(data = states, aes(x = long, y = lat, group = region), color = 'black', fill = NA) +
  scale_edge_colour_distiller(palette = 'RdBu', limits = c(-1,1)) +
  coord_equal() +
  theme_graph()
```
Looks like distance is correlated with residuals
```{r}
dat %>%
  filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[1,2]], type = 'response')) %>%
  as_tibble %>%
  qplot(distance, resid, data = ., geom = 'point', alpha = I(.1), color = as.factor(time))
```
```{r}
dat %>%
  filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[1,2]], type = 'response')) %>%
  as_tibble %>%
  qplot(abs(eof1), resid, data = ., geom = 'point', alpha = I(.1), color = as.factor(time))
```
```{r}
swsn %E>%
    filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[1,2]], type = 'response')) %>%
  filter(time == 1) %N>%
  mutate(centrality = centrality_eigen(weights = similarity)) %E>%
  mutate(cent = .N()$centrality[from] * .N()$centrality[to]) %>%
  as_tibble %>%
  qplot(cent, resid, data = ., geom = 'point', alpha = I(.1))
```

```{r}
swsn %E>%
    filter(similarity > 0) %>%
  mutate(resid = residuals(geo_models[[1,2]], type = 'response')) %>%
  filter(time == 3) %N>%
  mutate(centrality = centrality_eigen(weights = similarity)) %E>%
  mutate(cent = .N()$centrality[from] + .N()$centrality[to]) %>%
  as_tibble %>%
  qplot(cent, similarity, data = ., geom = 'point', alpha = I(.1))
```
